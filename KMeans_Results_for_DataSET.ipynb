{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myX_VwxKVo91"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Determine the optimal number of clusters using the Elbow method\n",
        "inertia = []\n",
        "k_values = range(1, 10)\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(diversity_df)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow graph\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_values, inertia, marker='o', linestyle='-')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal K')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_k = 3\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "diversity_df['Cluster'] = kmeans.fit_predict(diversity_df)\n",
        "\n",
        "# Chekin\n",
        "diversity_df.head()\n"
      ],
      "metadata": {
        "id": "V1ezdEtfVu94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CSV file again\n",
        "file_path = \"/mnt/data/pan_otutab.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Define functions for diversity indices\n",
        "def simpson_index(counts):\n",
        "    total = np.sum(counts)\n",
        "    if total == 0:\n",
        "        return 0\n",
        "    proportions = counts / total\n",
        "    return 1 - np.sum(proportions ** 2)\n",
        "\n",
        "# Dictionary to store diversity indices\n",
        "diversity_data = {}\n",
        "\n",
        "# Process each subject\n",
        "subject_columns = df.columns[1:]  # Exclude OTU_ID\n",
        "for subject in subject_columns:\n",
        "    subject_data = df[['OTU_ID', subject]].copy()\n",
        "\n",
        "    # Keep top 30 OTUs based on abundance\n",
        "    top_otus = subject_data.nlargest(30, subject)\n",
        "\n",
        "    # Compute diversity indices\n",
        "    shannon = entropy(top_otus[subject])  # Shannon Index\n",
        "    simpson = simpson_index(top_otus[subject].values)  # Simpson Index\n",
        "\n",
        "    diversity_data[subject] = {'Shannon': shannon, 'Simpson': simpson}\n",
        "\n",
        "# Convert to DataFrame\n",
        "diversity_df = pd.DataFrame.from_dict(diversity_data, orient='index')\n",
        "\n",
        "# Apply K-means clustering with an optimal number of clusters (choosing k=3)\n",
        "optimal_k = 3\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "diversity_df['Cluster'] = kmeans.fit_predict(diversity_df)\n",
        "\n",
        "# Merge cluster labels back to the original dataset (excluding OTU_ID for now)\n",
        "subject_cluster_map = diversity_df[['Cluster']].reset_index().rename(columns={'index': 'Subject'})\n",
        "otu_data = df.set_index('OTU_ID').T  # Transpose to align subjects as rows\n",
        "otu_data = otu_data.merge(subject_cluster_map, left_index=True, right_on='Subject').set_index('Subject')\n",
        "\n",
        "# Group by cluster and sum OTU abundances\n",
        "clustered_otus = otu_data.groupby('Cluster').sum().T\n",
        "\n",
        "# Extract top OTUs per cluster\n",
        "top_otus_per_cluster = {cluster: clustered_otus[cluster].nlargest(30).index.tolist() for cluster in clustered_otus.columns}\n",
        "\n",
        "top_otus_per_cluster\n"
      ],
      "metadata": {
        "id": "wZ0iybLQWs37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cluster 0:\n",
        "\n",
        "Prevotella copri\n",
        "Faecalibacterium prausnitzii\n",
        "Bacteroides plebeius\n",
        "Prevotella stercorea\n",
        "Pseudobutyrivibrio ruminis\n",
        "Parasutterella excrementihominis\n",
        "Megasphaera elsdenii\n",
        "\n",
        "##Cluster 1:\n",
        "\n",
        "Prevotella copri\n",
        "Faecalibacterium prausnitzii\n",
        "Haemophilus parainfluenzae\n",
        "Bacteroides plebeius\n",
        "Roseburia faecis\n",
        "Megasphaera elsdenii\n",
        "Lactobacillus rogosae\n",
        "\n",
        "##Cluster 2:\n",
        "\n",
        "Prevotella copri\n",
        "Faecalibacterium prausnitzii\n",
        "Bacteroides plebeius\n",
        "Haemophilus parainfluenzae\n",
        "Megasphaera elsdenii\n",
        "Prevotella stercorea\n",
        "Roseburia faecis"
      ],
      "metadata": {
        "id": "32zJiDibW-4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}